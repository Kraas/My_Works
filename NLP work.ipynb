{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Обучение модели word2vec [40 баллов]\n",
    "1. Объедините положительные и отрицательные твиты в один массив\n",
    "2. Разбейте всю коллекцию отзывов на предложения. Лемматизируйте все слова.\n",
    "3. Обучите по коллекции предложений word2vec\n",
    "4. Приведите несколько удачных и неудачных примеров решения стандартных тестов для word2vec:\n",
    "    - тест на определение ближайших слов\n",
    "    - тест на аналогии (мужчина – король : женщина – королева)\n",
    "    - тест на определение лишнего слова.\n",
    "5. Постройте визуализацию TSNE для топ-100 (или топ-500) слов и найдите осмысленные кластеры слов\n",
    "\n",
    "Ссылка на примеры визуализаций: https://towardsdatascience.com/game-of-thrones-word-embeddings-does-r-l-j-part-2-30290b1c0b4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'date', 'name', 'text', 'type', 'rep', 'rtw', 'fav', 'stcount', \n",
    "            'fol', 'frien', 'listcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv('Data/positive.csv', sep=';',  names=columns)\n",
    "negative = pd.read_csv('Data/negative.csv', sep=';',  names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive['is_positive'] = 1\n",
    "negative['is_positive'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtw</th>\n",
       "      <th>fav</th>\n",
       "      <th>stcount</th>\n",
       "      <th>fol</th>\n",
       "      <th>frien</th>\n",
       "      <th>listcount</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906762813579264</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906818262687744</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906858515398656</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        date             name  \\\n",
       "0  408906762813579264  1386325944  dugarchikbellko   \n",
       "1  408906818262687744  1386325957     nugemycejela   \n",
       "2  408906858515398656  1386325966          4post21   \n",
       "\n",
       "                                                text  type  rep  rtw  fav  \\\n",
       "0  на работе был полный пиддес :| и так каждое за...    -1    0    0    0   \n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...    -1    0    0    0   \n",
       "2  @elina_4post как говорят обещаного три года жд...    -1    0    0    0   \n",
       "\n",
       "   stcount  fol  frien  listcount  is_positive  \n",
       "0     8064  111     94          2            0  \n",
       "1       26   42     39          0            0  \n",
       "2      718   49    249          0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (positive.append(negative)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114911, 13), (111923, 13), (226834, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.shape, negative.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[['text', 'is_positive']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = re.compile('[А-Яа-я]+|\\.+|\\!+|\\?+|\\)+')\n",
    "word = re.compile('[А-Яа-я]+')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(re.findall(word, x.lower())))\n",
    "# symbol = re.compile('\\.+|\\!+|\\?+|\\)+') # окончания предложений\n",
    "# df['ttext'] = df['ttext'].apply(lambda x: re.sub(symbol, '.', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота но поверь у нас то же самое о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>да все таки он немного похож на него но мой ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ну ты идиотка я испугалась за тебя</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кто то в углу сидит и погибает от голода а мы ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вот что значит страшилка но блин посмотрев все...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive\n",
       "0  хоть я и школота но поверь у нас то же самое о...            1\n",
       "1  да все таки он немного похож на него но мой ма...            1\n",
       "2                 ну ты идиотка я испугалась за тебя            1\n",
       "3  кто то в углу сидит и погибает от голода а мы ...            1\n",
       "4  вот что значит страшилка но блин посмотрев все...            1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также']\n",
    "def  stop_words(text, stopwords = stopw):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords and len(token) > 2])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2 = MorphAnalyzer()\n",
    "\n",
    "def  remove_lemm(text):\n",
    "    try:\n",
    "        return \" \".join([pm2.parse(token)[0].normal_form for token in text.split()])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    no_stopwords = stop_words(text)\n",
    "    lemmas = remove_lemm(no_stopwords)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[школотый, поверь, самый, общество, профилиров...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[таки, немного, похожий, мальчик, равно]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[идиотка, испугаться]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[угол, сидеть, погибать, голод, порция, взять,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[значит, страшилка, блин, посмотреть, часть, с...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive\n",
       "0  [школотый, поверь, самый, общество, профилиров...            1\n",
       "1           [таки, немного, похожий, мальчик, равно]            1\n",
       "2                              [идиотка, испугаться]            1\n",
       "3  [угол, сидеть, погибать, голод, порция, взять,...            1\n",
       "4  [значит, страшилка, блин, посмотреть, часть, с...            1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df.text, size=100, window=3, min_count=20, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь посмотрим ближайшие слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('приложение', 0.9386524558067322),\n",
       " ('блог', 0.9179162383079529),\n",
       " ('ссылка', 0.9177023768424988)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"сайт\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('капельница', 0.9647878408432007),\n",
       " ('затем', 0.9569962024688721),\n",
       " ('стоя', 0.9561183452606201)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"голод\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('блиина', 0.7782334685325623),\n",
       " ('ааа', 0.7753502130508423),\n",
       " ('тож', 0.7673264741897583)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"блин\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим аналоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('вод', 0.8576784133911133),\n",
       " ('холод', 0.8381669521331787),\n",
       " ('лёд', 0.8151445388793945)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"жара\", \"зима\"], negative=[\"лето\"])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('синдромканделаки', 0.8908705711364746),\n",
       " ('журналист', 0.8765182495117188),\n",
       " ('ресурс', 0.8643521070480347)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"сша\", \"путин\"], negative=[\"россия\"])[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найдем лишнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'радуга'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"чатиться писать общаться радуга\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'планета'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"планета космос байконур париж\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем полученное пространство векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "all_words = FreqDist()\n",
    "for word in df['text']:\n",
    "    all_words.update(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = []\n",
    "\n",
    "for i in all_words.most_common(300):\n",
    "    top_words.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['хотеть', 'такой', 'сегодня', 'очень', 'просто', 'человек', 'знать', 'любить', 'завтра', 'самый']\n"
     ]
    }
   ],
   "source": [
    "top_words = [w for w in top_words if len(w) > 4]\n",
    "print (top_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "top_words_vec = model[top_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "top_words_tsne = tsne.fit_transform(top_words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1184\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1184\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1184\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1184' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1184\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1184\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1184\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1184' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1184\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"46cdcb2d-dbc4-48ea-b487-77e848bf31a6\" data-root-id=\"1186\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"3947e409-31e9-4c52-8e2e-5f474fac33aa\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1196\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1201\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1196\",\"type\":\"LinearAxis\"},{\"id\":\"1200\",\"type\":\"Grid\"},{\"id\":\"1201\",\"type\":\"LinearAxis\"},{\"id\":\"1205\",\"type\":\"Grid\"},{\"id\":\"1219\",\"type\":\"GlyphRenderer\"},{\"id\":\"1221\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"1185\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1210\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1188\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1192\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1190\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1194\",\"type\":\"LinearScale\"}},\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1239\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1188\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1217\",\"type\":\"Scatter\"},{\"attributes\":{\"source\":{\"id\":\"1215\",\"type\":\"ColumnDataSource\"}},\"id\":\"1220\",\"type\":\"CDSView\"},{\"attributes\":{\"plot\":null,\"text\":\"word2vec T-SNE for most common words\"},\"id\":\"1185\",\"type\":\"Title\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1205\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1202\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1215\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1217\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1218\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1220\",\"type\":\"CDSView\"}},\"id\":\"1219\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"1215\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1221\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1192\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1242\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1206\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1243\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1194\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"data\":{\"names\":[\"\\u0445\\u043e\\u0442\\u0435\\u0442\\u044c\",\"\\u0442\\u0430\\u043a\\u043e\\u0439\",\"\\u0441\\u0435\\u0433\\u043e\\u0434\\u043d\\u044f\",\"\\u043e\\u0447\\u0435\\u043d\\u044c\",\"\\u043f\\u0440\\u043e\\u0441\\u0442\\u043e\",\"\\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a\",\"\\u0437\\u043d\\u0430\\u0442\\u044c\",\"\\u043b\\u044e\\u0431\\u0438\\u0442\\u044c\",\"\\u0437\\u0430\\u0432\\u0442\\u0440\\u0430\",\"\\u0441\\u0430\\u043c\\u044b\\u0439\",\"\\u0432\\u043e\\u043e\\u0431\\u0449\\u0435\",\"\\u0434\\u0435\\u043b\\u0430\\u0442\\u044c\",\"\\u0445\\u043e\\u0440\\u043e\\u0448\\u0438\\u0439\",\"\\u0441\\u043f\\u0430\\u0441\\u0438\\u0431\\u043e\",\"\\u043d\\u043e\\u0432\\u044b\\u0439\",\"\\u043f\\u043e\\u0447\\u0435\\u043c\\u0443\",\"\\u0441\\u043a\\u0430\\u0437\\u0430\\u0442\\u044c\",\"\\u0434\\u0443\\u043c\\u0430\\u0442\\u044c\",\"\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u0442\\u044c\",\"\\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0439\",\"\\u0432\\u0440\\u0435\\u043c\\u044f\",\"\\u0441\\u043f\\u0430\\u0442\\u044c\",\"\\u0441\\u0438\\u0434\\u0435\\u0442\\u044c\",\"\\u043f\\u0438\\u0441\\u0430\\u0442\\u044c\",\"\\u0436\\u0438\\u0437\\u043d\\u044c\",\"\\u0441\\u0434\\u0435\\u043b\\u0430\\u0442\\u044c\",\"\\u0448\\u043a\\u043e\\u043b\\u0430\",\"\\u043d\\u0430\\u0441\\u0442\\u0440\\u043e\\u0435\\u043d\\u0438\\u0435\",\"\\u0433\\u043e\\u0432\\u043e\\u0440\\u0438\\u0442\\u044c\",\"\\u043a\\u0430\\u043a\\u043e\\u0439\",\"\\u0436\\u0434\\u0430\\u0442\\u044c\",\"\\u0431\\u043e\\u043b\\u0435\\u0442\\u044c\",\"\\u043b\\u044e\\u0431\\u0438\\u043c\\u044b\\u0439\",\"\\u043d\\u0430\\u043f\\u0438\\u0441\\u0430\\u0442\\u044c\",\"\\u0445\\u043e\\u0442\\u0435\\u0442\\u044c\\u0441\\u044f\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\",\"\\u043f\\u043e\\u0439\\u0442\\u0438\",\"\\u0432\\u0438\\u0434\\u0435\\u0442\\u044c\",\"\\u043f\\u043e\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u0442\\u044c\",\"\\u043d\\u0438\\u043a\\u0442\\u043e\",\"\\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0439\",\"\\u0441\\u0442\\u0430\\u0442\\u044c\",\"\\u0434\\u043e\\u0431\\u0440\\u044b\\u0439\",\"\\u043f\\u043e\\u043d\\u044f\\u0442\\u044c\",\"\\u043a\\u0443\\u043f\\u0438\\u0442\\u044c\",\"\\u043f\\u043e\\u043d\\u0438\\u043c\\u0430\\u0442\\u044c\",\"\\u043d\\u0430\\u0439\\u0442\\u0438\",\"\\u043d\\u0435\\u0434\\u0435\\u043b\\u044f\",\"\\u043a\\u0430\\u0436\\u0434\\u044b\\u0439\",\"\\u043d\\u0440\\u0430\\u0432\\u0438\\u0442\\u044c\\u0441\\u044f\",\"\\u0441\\u043a\\u0443\\u0447\\u0430\\u0442\\u044c\",\"\\u0441\\u043a\\u043e\\u0440\\u043e\",\"\\u043d\\u0443\\u0436\\u043d\\u043e\",\"\\u0434\\u0430\\u0432\\u0430\\u0442\\u044c\",\"\\u0432\\u0447\\u0435\\u0440\\u0430\",\"\\u0437\\u0430\\u0431\\u044b\\u0442\\u044c\",\"\\u0447\\u0438\\u0442\\u0430\\u0442\\u044c\",\"\\u043f\\u043b\\u043e\\u0445\\u043e\",\"\\u0440\\u0430\\u0431\\u043e\\u0442\\u0430\\u0442\\u044c\",\"\\u0444\\u0438\\u043b\\u044c\\u043c\",\"\\u043e\\u0441\\u0442\\u0430\\u0442\\u044c\\u0441\\u044f\",\"\\u0432\\u0435\\u0447\\u0435\\u0440\",\"\\u0445\\u043e\\u0434\\u0438\\u0442\\u044c\",\"\\u043d\\u0430\\u0434\\u0435\\u044f\\u0442\\u044c\\u0441\\u044f\",\"\\u0434\\u043e\\u043c\\u043e\\u0439\",\"\\u0442\\u0435\\u043b\\u0435\\u0444\\u043e\\u043d\",\"\\u043d\\u043e\\u0440\\u043c\\u0430\\u043b\\u044c\\u043d\\u044b\\u0439\",\"\\u043f\\u0440\\u0430\\u0432\\u0434\\u0430\",\"\\u043d\\u0443\\u0436\\u043d\\u044b\\u0439\",\"\\u0440\\u0430\\u0432\\u043d\\u043e\",\"\\u0441\\u043b\\u043e\\u0432\\u043e\",\"\\u0432\\u0440\\u043e\\u0434\\u0435\",\"\\u0434\\u0440\\u0443\\u0433\\u043e\\u0439\",\"\\u0443\\u043b\\u0438\\u0446\\u0430\",\"\\u0443\\u0432\\u0438\\u0434\\u0435\\u0442\\u044c\",\"\\u043a\\u0430\\u0436\\u0435\\u0442\\u0441\\u044f\",\"\\u043f\\u0440\\u0438\\u0432\\u0435\\u0442\",\"\\u0444\\u043e\\u0442\\u043a\\u0430\",\"\\u043f\\u043e\\u043c\\u043d\\u0438\\u0442\\u044c\",\"\\u043d\\u0430\\u0447\\u0430\\u0442\\u044c\",\"\\u043a\\u0440\\u0443\\u0442\\u043e\",\"\\u043c\\u0438\\u043d\\u0443\\u0442\\u0430\",\"\\u0440\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435\",\"\\u043c\\u0435\\u0441\\u0442\\u043e\",\"\\u043f\\u0430\\u0440\\u0435\\u043d\\u044c\",\"\\u0434\\u043e\\u043b\\u0436\\u043d\\u044b\\u0439\",\"\\u0438\\u0433\\u0440\\u0430\\u0442\\u044c\",\"\\u0441\\u043d\\u043e\\u0432\\u0430\",\"\\u0433\\u043e\\u043b\\u043e\\u0432\\u0430\",\"\\u043d\\u043e\\u0432\\u043e\\u0433\\u043e\\u0434\\u043d\\u0438\\u0439\",\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u043e\\u0439\",\"\\u0434\\u0430\\u0432\\u043d\\u043e\",\"\\u0434\\u0435\\u0432\\u0443\\u0448\\u043a\\u0430\",\"\\u0435\\u0445\\u0430\\u0442\\u044c\",\"\\u0440\\u0435\\u0448\\u0438\\u0442\\u044c\",\"\\u0442\\u043e\\u0447\\u043d\\u043e\",\"\\u043f\\u0440\\u0438\\u0435\\u0445\\u0430\\u0442\\u044c\",\"\\u0432\\u044b\\u0445\\u043e\\u0434\\u043d\\u043e\\u0439\",\"\\u0440\\u0430\\u043d\\u043d\\u0438\\u0439\",\"\\u043f\\u043e\\u0434\\u0430\\u0440\\u043e\\u043a\",\"\\u0432\\u044b\\u0439\\u0442\\u0438\",\"\\u0441\\u0440\\u0430\\u0437\\u0443\",\"\\u043a\\u043b\\u0430\\u0441\\u0441\",\"\\u043a\\u0441\\u0442\\u0430\\u0442\\u0438\",\"\\u043d\\u043e\\u0432\\u043e\\u0435\",\"\\u0431\\u043e\\u044f\\u0442\\u044c\\u0441\\u044f\",\"\\u043b\\u0430\\u0434\\u043d\\u044b\\u0439\",\"\\u043b\\u0435\\u043d\\u0442\\u0430\",\"\\u043c\\u0430\\u043b\\u0435\\u043d\\u044c\\u043a\\u0438\\u0439\",\"\\u0432\\u043e\\u043f\\u0440\\u043e\\u0441\",\"\\u0447\\u0443\\u0432\\u0441\\u0442\\u0432\\u043e\\u0432\\u0430\\u0442\\u044c\",\"\\u043b\\u044e\\u0431\\u043e\\u0432\\u044c\",\"\\u0434\\u0435\\u043d\\u044c\\u0433\\u0430\",\"\\u0433\\u043e\\u0440\\u043e\\u0434\",\"\\u0432\\u0437\\u044f\\u0442\\u044c\",\"\\u0433\\u043b\\u0430\\u0432\\u043d\\u044b\\u0439\",\"\\u043d\\u0435\\u043d\\u0430\\u0432\\u0438\\u0434\\u0435\\u0442\\u044c\",\"\\u043a\\u043e\\u043d\\u0435\\u0446\",\"\\u0441\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043f\\u043e\\u043b\\u043e\\u0432\\u0438\\u043d\\u0430\",\"\\u0441\\u043b\\u0443\\u0448\\u0430\\u0442\\u044c\",\"\\u0431\\u044b\\u0432\\u0430\\u0442\\u044c\",\"\\u043f\\u0440\\u043e\\u0441\\u0442\\u0438\\u0442\\u044c\",\"\\u0441\\u043c\\u043e\\u0447\\u044c\",\"\\u043d\\u0430\\u0432\\u0435\\u0440\\u043d\\u043e\\u0435\",\"\\u0431\\u043b\\u044f\\u0442\\u044c\",\"\\u043f\\u043e\\u043d\\u0440\\u0430\\u0432\\u0438\\u0442\\u044c\\u0441\\u044f\",\"\\u0441\\u0438\\u043b\\u044c\\u043d\\u043e\",\"\\u0441\\u0442\\u043e\\u043b\\u044c\\u043a\\u043e\",\"\\u043f\\u0440\\u0438\\u0448\\u043b\\u044b\\u0439\",\"\\u043c\\u0435\\u0441\\u044f\\u0446\",\"\\u0434\\u0435\\u0432\\u043e\\u0447\\u043a\\u0430\",\"\\u043f\\u0440\\u0438\\u0439\\u0442\\u0438\",\"\\u0430\\u0445\\u0430\\u0445\\u0438\",\"\\u0440\\u0435\\u0431\\u0451\\u043d\\u043e\\u043a\",\"\\u043a\\u0440\\u0443\\u0442\\u043e\\u0439\",\"\\u043c\\u043e\\u043c\\u0435\\u043d\\u0442\",\"\\u043d\\u043e\\u0440\\u043c\\u0430\",\"\\u0437\\u043d\\u0430\\u0447\\u0438\\u0442\",\"\\u043a\\u0440\\u0430\\u0441\\u0438\\u0432\\u044b\\u0439\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u0442\\u044c\\u0441\\u044f\",\"\\u0440\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439\",\"\\u043f\\u0440\\u043e\\u0441\\u043d\\u0443\\u0442\\u044c\\u0441\\u044f\",\"\\u043f\\u0438\\u0437\\u0434\\u0435\\u0446\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0435\\u0441\\u043d\\u043e\",\"\\u043c\\u0443\\u0437\\u044b\\u043a\\u0430\",\"\\u0436\\u0430\\u043b\\u043a\\u043e\",\"\\u044d\\u043a\\u0437\\u0430\\u043c\\u0435\\u043d\",\"\\u043e\\u0431\\u0438\\u0434\\u043d\\u044b\\u0439\",\"\\u0443\\u0441\\u043f\\u0435\\u0442\\u044c\",\"\\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u044f\",\"\\u0433\\u0443\\u043b\\u044f\\u0442\\u044c\",\"\\u0443\\u0437\\u043d\\u0430\\u0442\\u044c\",\"\\u0447\\u0443\\u0432\\u0441\\u0442\\u0432\\u043e\",\"\\u0440\\u043e\\u0441\\u0441\\u0438\\u044f\",\"\\u0441\\u0447\\u0430\\u0441\\u0442\\u0438\\u0435\",\"\\u043f\\u0440\\u0438\\u044f\\u0442\\u043d\\u043e\",\"\\u0437\\u0430\\u043a\\u043e\\u043d\\u0447\\u0438\\u0442\\u044c\\u0441\\u044f\",\"\\u0440\\u0435\\u0431\\u044f\\u0442\\u0430\",\"\\u043f\\u0440\\u0430\\u0437\\u0434\\u043d\\u0438\\u043a\",\"\\u043f\\u0440\\u0438\\u0439\\u0442\\u0438\\u0441\\u044c\",\"\\u0441\\u0435\\u0440\\u0438\\u044f\",\"\\u0432\\u0441\\u043f\\u043e\\u043c\\u043d\\u0438\\u0442\\u044c\",\"\\u0443\\u0447\\u0438\\u0442\\u044c\",\"\\u043f\\u043e\\u043b\\u0443\\u0447\\u0438\\u0442\\u044c\",\"\\u043d\\u0435\\u043c\\u043d\\u043e\\u0433\\u043e\",\"\\u0441\\u043a\\u0443\\u0447\\u043d\\u043e\",\"\\u0441\\u0445\\u043e\\u0434\\u0438\\u0442\\u044c\",\"\\u0443\\u0436\\u0430\\u0441\\u043d\\u043e\",\"\\u0434\\u043e\\u043b\\u0433\\u043e\",\"\\u043e\\u0442\\u043b\\u0438\\u0447\\u043d\\u044b\\u0439\",\"\\u043f\\u0440\\u043e\\u0439\\u0442\\u0438\",\"\\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u0430\",\"\\u043f\\u0435\\u0441\\u043d\\u044f\",\"\\u0443\\u0441\\u0442\\u0430\\u0442\\u044c\",\"\\u043f\\u043e\\u0435\\u0445\\u0430\\u0442\\u044c\",\"\\u043f\\u043b\\u043e\\u0445\\u043e\\u0439\",\"\\u043c\\u0438\\u043b\\u044b\\u0439\",\"\\u043f\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u044c\",\"\\u043f\\u043e\\u0434\\u0440\\u0443\\u0433\\u0430\",\"\\u0441\\u0442\\u043e\\u0438\\u0442\\u044c\",\"\\u043a\\u0430\\u043d\\u0438\\u043a\\u0443\\u043b\\u044b\",\"\\u043d\\u0430\\u0447\\u0438\\u043d\\u0430\\u0442\\u044c\",\"\\u043f\\u043e\\u043c\\u043e\\u0447\\u044c\",\"\\u0437\\u0430\\u0431\\u043e\\u043b\\u0435\\u0442\\u044c\",\"\\u0443\\u0447\\u0438\\u0442\\u044c\\u0441\\u044f\",\"\\u0445\\u043e\\u043b\\u043e\\u0434\\u043d\\u044b\\u0439\",\"\\u0445\\u0432\\u0430\\u0442\\u0430\\u0442\\u044c\",\"\\u0438\\u043c\\u0435\\u043d\\u043d\\u043e\",\"\\u043a\\u043b\\u0430\\u0441\\u0441\\u043d\\u044b\\u0439\",\"\\u0432\\u043c\\u0435\\u0441\\u0442\\u0435\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u043d\\u0435\\u0442\",\"\\u0441\\u043b\\u0438\\u0448\\u043a\\u043e\\u043c\",\"\\u0432\\u0435\\u0440\\u0438\\u0442\\u044c\",\"\\u043f\\u0443\\u0441\\u0442\\u044c\",\"\\u043f\\u043e\\u0433\\u043e\\u0434\\u0430\",\"\\u0438\\u043d\\u0442\\u0435\\u0440\\u0435\\u0441\\u043d\\u044b\\u0439\",\"\\u043c\\u0430\\u0448\\u0438\\u043d\\u0430\",\"\\u0442\\u0432\\u0438\\u0442\\u0442\\u0435\\u0440\\u0435\\u0442\\u044c\",\"\\u043e\\u0444\\u0438\\u0433\\u0435\\u043d\\u043d\\u044b\\u0439\",\"\\u0443\\u043c\\u0435\\u0442\\u044c\",\"\\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0441\\u043d\\u044b\\u0439\",\"\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430\",\"\\u043f\\u043b\\u0430\\u043a\\u0430\\u0442\\u044c\",\"\\u0441\\u0447\\u0430\\u0441\\u0442\\u043b\\u0438\\u0432\\u044b\\u0439\",\"\\u043e\\u0442\\u043b\\u0438\\u0447\\u043d\\u043e\",\"\\u043f\\u043e\\u0445\\u043e\\u0434\",\"\\u0436\\u0435\\u043b\\u0430\\u043d\\u0438\\u0435\",\"\\u043f\\u043e\\u044d\\u0442\\u043e\\u043c\\u0443\",\"\\u043f\\u044f\\u0442\\u043d\\u0438\\u0446\\u0430\",\"\\u0432\\u0438\\u0434\\u0435\\u043e\",\"\\u043f\\u043e\\u0448\\u043b\\u044b\\u0439\",\"\\u0443\\u043c\\u0435\\u0440\\u0435\\u0442\\u044c\",\"\\u043d\\u0438\\u043a\\u0430\\u043a\",\"\\u0434\\u043e\\u0440\\u043e\\u0433\\u043e\\u0439\",\"\\u0441\\u0434\\u0430\\u0442\\u044c\",\"\\u0440\\u043e\\u0434\\u0438\\u0442\\u0435\\u043b\\u044c\",\"\\u043f\\u043e\\u043b\\u043d\\u044b\\u0439\",\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0430\",\"\\u043f\\u0440\\u0438\\u0445\\u043e\\u0434\\u0438\\u0442\\u044c\",\"\\u0437\\u043d\\u0430\\u0435\\u0448\\u044c\",\"\\u043d\\u043e\\u0432\\u043e\\u0441\\u0442\\u044c\",\"\\u0432\\u0441\\u0442\\u0430\\u0442\\u044c\",\"\\u0431\\u044b\\u0441\\u0442\\u0440\\u043e\",\"\\u043f\\u043e\\u043d\\u0435\\u0434\\u0435\\u043b\\u044c\\u043d\\u0438\\u043a\",\"\\u0433\\u043e\\u043b\\u043e\\u0441\",\"\\u043f\\u043e\\u0434\\u0443\\u043c\\u0430\\u0442\\u044c\",\"\\u043c\\u044b\\u0441\\u043b\\u044c\",\"\\u0443\\u0442\\u0440\\u043e\\u043c\",\"\\u0443\\u0436\\u0430\\u0441\\u043d\\u044b\\u0439\"],\"x1\":{\"__ndarray__\":\"kJgmwD0QDEDVB5jAt9vtQFQgmz8SeUhBMNKMQBtrEkFGr6HACtRKQF2eVz/u/0LBIbT0QK9iaUBBum1AH8CdQDAlyUA8VkNAs6fCQE9Rzz8NVUVBxHbKwHxIfj82XEjBNNU0QXsnRMFxgcnAq9iawM4pxUDDPQRB4LUavoYSQMBqBwRBjolCwZMTJsCSKn7AyQ+bwIfKnUBOO8VAP7XUQD51LEFXi91AnRCrQD0bf0DiqhrAndOYQFJr/j4qUfHAFlIFPsprPkHnJKFAE++fwLKm3L6wlfxAoqQ5wA80nz+NqEzBsf6vv4fyyj9skw1B8yjKvzcPqMBq48fAkOP4PheIzsBa91k/4nKHvxqGt0Bv1MY/psX4PxrKHUGAKg0/8RwLQK1tGMFOQpZA6r1pQE1AQ0B6+/tAQRijQNvd2z5Sa1w7s/P5wNtawEAZLwXA3FQ2QcJ4+z8zfY1AQ+JJwI6tXsAQd8lAk4D1QMFBXj9EITtB/1G2wEe/EcDnggpAJWe0wFXkkMBjuw0/N4dIwPLPdsAbAT4+EnTiwLb8M0DwwG9AMm+DQIJ7I0DN5TdA72PWQNeBM0C7nva/1/C+QF1fMr+SwhDA7zK2v0E00kBUsxi/Dl7Ov4BPJkAc0e3AXo5/QDTWD0GTXDFAe0ANwOAnDEDGUDq/2cc8QUsB80DJjylAqg7WwBy49MDUGCFBEVHKwLZBTEA1uRpBnCUTQYTEOkHODpC/nGr6Py0qH0EISnY//oYXwXRPtcAFpsu/kxJsQGGOdUATh+1AYFUTwZdYnUAEZjrAE/0Wwfhl7cASh4ZAV80tQbwWib/yP7tAOzsRQWbozL9gt8Y/bF91wKpTo79FFhBBFdeOQIBUIsGhsA3BmXPUPV+prDyE4J3AqsobwEZ3bkARUO5Athnav88cLkBifvJAEpAewChEq8DH+PFAMVARQb8ECsGs2ypBDQK3vc64hsCDPQc/mJ0YQOWWLMBuAtvA34UXwUje6kCyCWlAuPEOQTMJgUA0ZKQ/gybXQF++okAUQrtAHVccwVJxH0HMaRPAHnYtQNZPEkHey69AvcrzQCWx0UC7ZrxAsSXlQIrO5L7yjwfA/7mJwOOa0D93RY3AkUoAQSbhnMDgu8JA/KaMv7/U80BaGxTBPksfQd5SEcDOWxTANorXwHVkjECbAVBA9Ee4wOD1WL/uF5LARd2dQNYjWEDCCSdBJWunwHLD7EA=\",\"dtype\":\"float32\",\"shape\":[230]},\"x2\":{\"__ndarray__\":\"cH01weda8kCCKWNAdjH1PlSKdT9YXOQ/FI0GwNjwfkBhFIpAevb/QGMkCj+YGytAt4gFQQ+Wr0ASYUBBiAA9wCkUJcC454O/d+cewdILWsBM6yfAJ2QcvvN9G8E9RY6/iOWxvg68K0B7lBpAWSUPQYvYGsDfcoHASI2+QD+OTEDy7NBAJoB/v3bVNcGz8bC+lnF3wOGRw8BAqx7BVEh7wBptoMBr7b2+9aEMQUC2C8AfOrHABU2iv20ut8B+wu1A2FoNQVmWt0CSjM9Abi4NwSSHWMC7UwHAo7nuvyuQlMAjfZq/9BkLQM//7MDKmALBh9/bQHUszkAHKY3A5d9pQMpWAcBVC/PAoUqxv/dAUT5yBqNAPMscPhWlpb/gMmQ/1/w7wBzDgMBOHbjAW/jAvo/hlkANNOnAC9uLwLCuKL+iIChAF/bSQEnltEB3RwXBLJkTQJFL0b9mXQnB7zdfPuLS+T8bVzRByMKYQJFSI8BzHBBAo/m6wIzLYMBxGKa/dTbQwKlBzECwlcq/qNQJQYX9vMAj7P+/cOxHQBYuor3HFUBBDp74PnjaYz8iL4VA3HlQQHr2lsCM580/JE6JQIN3tMBLFfvA20imwHWN4ECUrRc/7t3EQNz4B8Bdra1An2wRwYBn4L7//ts/ucRKwO8kEr/1zKi+567FQIgH1z+iW+pAq2bWwNWb6kCFxj1AR/fTwCRZAT+S/v8/7nwJQV+wAcA8JQK/TUtCv87N30B7GiZAIdJIQHgKAD5edx0/wZ9DwPFNFMFXGDhA7tGjP4teYb7T6zPAtA1DQAKjT8BCiZHAUifCv6Ta3sDklJdAShaeQJfZukCyTlVAP4X3QBeSe8A6/wPBd+ahwJaXDUBRBeq+8J/tP5NBHMEm+KPAKwMIQDtUvT8KmCJBX1OuQE9Vd8ByUPLAtR76PxrTwsCtDg1BIF6eQGfFPr8MAQRAPb+JwD9w0EBO2eS+4OMPQKPuMUBC3hRAoASGwHBrcUBE/oK/sgYKQdgwIECU3e/AN47HPF97WkARUItAJi1mwICPCUEmEeLAGULFwHosG0HwTLC/wc8UQbN/vsCSTrs/QUS9QMiWJ0DH/gY+Qgn5v3tRVL/CRK1A5XjuwCmzc8AsvBxA44T0v+jGvUAmYpY/auvjP0M7br06sOnAydbbwKu9er8TdFBAW32nPNqChEB7oq5AgRapPxt/+r9O7LS/JMvlPr24E0E=\",\"dtype\":\"float32\",\"shape\":[230]}},\"selected\":{\"id\":\"1243\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1242\",\"type\":\"UnionRenderers\"}},\"id\":\"1215\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1207\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1241\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1197\",\"type\":\"BasicTicker\"}},\"id\":\"1196\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1241\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1208\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1197\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1209\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":{\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1197\",\"type\":\"BasicTicker\"}},\"id\":\"1200\",\"type\":\"Grid\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1218\",\"type\":\"Scatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1239\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1186\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1201\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"1190\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1206\",\"type\":\"PanTool\"},{\"id\":\"1207\",\"type\":\"WheelZoomTool\"},{\"id\":\"1208\",\"type\":\"ResetTool\"},{\"id\":\"1209\",\"type\":\"SaveTool\"}]},\"id\":\"1210\",\"type\":\"Toolbar\"}],\"root_ids\":[\"1186\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
       "  var render_items = [{\"docid\":\"3947e409-31e9-4c52-8e2e-5f474fac33aa\",\"roots\":{\"1186\":\"46cdcb2d-dbc4-48ea-b487-77e848bf31a6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1186"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=top_words_tsne[:,0],\n",
    "                                    x2=top_words_tsne[:,1],\n",
    "                                    names=top_words))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если увеличить и рассмотреть 'сгустки' векторов, то они в основном на похожие тематики. Например: в верхнем левом углу: минута, неделя, месяц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Анализ тональности [60 баллов]\n",
    "\n",
    "Отделите 25% положительных и 25% отрицательных твитов как тестовую выборку. Обучите классификатор, отличающий положительно окрашенные твиты от отрицательно окрашенных на обучающей выборке (оставшиеся 75%) и оцените их accuracy на выборке тестовой. А лучше несколько классификаторов, устроенных по-разному. Если у вас получилось несколько очень похожих классификаторов (скажем, один и тот же класс из sklearn с разными гиперпараметрами), они будут считаться не разными методами, а разными версиями одного метода и учитываться будет только лучшая версия. Тем не менее, по возможности не удаляйте их из ноутбука! Очень интересно, как вы пришли к результату, к которому вы пришли.\n",
    "\n",
    "Можно использовать предобученные модели. К обучающей выборке можно добавить какие-нибудь ещё данные, которые вы сами где-то найдёте, а можно наоборот - вообще её не использовать (сделать классификатор, основанный на вручную написанных правилах).\n",
    "\n",
    "Если у вас будет хотя бы один работающий классификатор, ваша оценка за часть 2 будет вычислена по формуле:\n",
    "\n",
    "$$\n",
    "\\min( 10 + \\sum_i (a_i - 50); 60 )\n",
    "$$\n",
    "\n",
    "где $a_i$ - accuracy одного из ваших (разных!) методов на тестовой выборке.\n",
    "\n",
    "В этом задании (при желании) можно применить все знания, полученные за курс:\n",
    "- Морфология и синтаксический парсинг\n",
    "- Тематические модели\n",
    "- Bag of words и TF/IDF\n",
    "- Дистрибутивная семантика\n",
    "- Классические классификаторы (RandomForest)\n",
    "- Нейронные классификаторы\n",
    "- Языковые модели\n",
    "- Attention\n",
    "- Извлечение терминов\n",
    "\n",
    "А так же задавать в слаке любые вопросы\n",
    "\n",
    "Как видно из формулы, у вас есть выбор - брать количеством или качеством :)\n",
    "\n",
    "Удачи и да пребудет с вами BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vec(sent, w2v = model):\n",
    "    vec = np.array([w2v[w] for w in sent if w in w2v])\n",
    "    if len(vec):\n",
    "        return(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        return(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['mean_vec'] = df['text'].apply(lambda x: sent_to_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>mean_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[школотый, поверь, самый, общество, профилиров...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.21145439, -0.52777493, -0.2547268, 0.464470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[таки, немного, похожий, мальчик, равно]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0074229212, -0.14906716, -0.09295411, -0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[идиотка, испугаться]</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.17222708, -0.1628049, -0.15499324, 0.09118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[угол, сидеть, погибать, голод, порция, взять,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.22343801, 0.098665655, -0.14157748, 0.3297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[значит, страшилка, блин, посмотреть, часть, с...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.13393934, -0.20025873, -0.06487245, 0.0321...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive  \\\n",
       "0  [школотый, поверь, самый, общество, профилиров...            1   \n",
       "1           [таки, немного, похожий, мальчик, равно]            1   \n",
       "2                              [идиотка, испугаться]            1   \n",
       "3  [угол, сидеть, погибать, голод, порция, взять,...            1   \n",
       "4  [значит, страшилка, блин, посмотреть, часть, с...            1   \n",
       "\n",
       "                                            mean_vec  \n",
       "0  [0.21145439, -0.52777493, -0.2547268, 0.464470...  \n",
       "1  [0.0074229212, -0.14906716, -0.09295411, -0.29...  \n",
       "2  [-0.17222708, -0.1628049, -0.15499324, 0.09118...  \n",
       "3  [-0.22343801, 0.098665655, -0.14157748, 0.3297...  \n",
       "4  [-0.13393934, -0.20025873, -0.06487245, 0.0321...  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['mean_vec'].tolist()\n",
    "X_test = X_test['mean_vec'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "max_depth = [5, 7, 9, 12, 15]\n",
    "min_samples_leaf = [5, 7, 9, 12, 15]\n",
    "grid_params = {'max_depth':max_depth, 'min_samples_leaf':min_samples_leaf}\n",
    "grid_rf = GridSearchCV(rf, grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [5, 7, 9, 12, 15], 'min_samples_leaf': [5, 7, 9, 12, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_rf.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6387698601632897"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим как линейный алгоритм справится с этой задачей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "log = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "grid_params = {'C': [0.01, 0.05, 0.1, 0.5, 1, 1.5]}\n",
    "grid_log = GridSearchCV(log, grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='warn', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.01, 0.05, 0.1, 0.5, 1, 1.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.621224144315717"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_log.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### взвесим наши вектора с помощью tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 30)\n",
    "df_tfidf = tfidf.fit_transform([' '.join(tokens) for tokens in df['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48812934, 0.53727708, 0.47548669, 0.2908606 , 0.40295856])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[0][table[0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.columns = ['ind', 'text', 'is_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vec_with_tfidf(sent, num, w2v = model):\n",
    "    list_names = tfidf.get_feature_names()\n",
    "    vec_tfidf = []\n",
    "    for w in sent:\n",
    "        if w in w2v:\n",
    "            try:\n",
    "                ind = list_names.index(w)\n",
    "                coef = table[num][ind]\n",
    "                vec_tfidf.append(w2v[w] * coef)\n",
    "            except:\n",
    "                vec_tfidf.append(np.zeros(100))\n",
    "    vec = np.array(vec_tfidf)\n",
    "    if len(vec):\n",
    "        return (np.mean(vec, axis=0))\n",
    "    else:\n",
    "        return(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n",
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df['mean_vec_tfidf'] = df.apply(lambda x: sent_to_vec_with_tfidf(x.text, x.ind), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['mean_vec_tfidf'].tolist()\n",
    "X_test = X_test['mean_vec_tfidf'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, max_depth=20, min_samples_leaf=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6335502301222028"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получили практически такой же результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## теперь попробуем другой embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import WindowsPath\n",
    "bpemb_ru = BPEmb(lang=\"ru\", dim=100, cache_dir = WindowsPath('C:\\My Programs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_ru_2 = BPEmb(lang=\"ru\", dim=50, cache_dir = WindowsPath('C:\\My Programs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (positive.append(negative)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[['text', 'is_positive']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = re.compile('[А-Яа-я]+')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(re.findall(word, x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота но поверь у нас то же самое о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>да все таки он немного похож на него но мой ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ну ты идиотка я испугалась за тебя</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кто то в углу сидит и погибает от голода а мы ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вот что значит страшилка но блин посмотрев все...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive\n",
       "0  хоть я и школота но поверь у нас то же самое о...            1\n",
       "1  да все таки он немного похож на него но мой ма...            1\n",
       "2                 ну ты идиотка я испугалась за тебя            1\n",
       "3  кто то в углу сидит и погибает от голода а мы ...            1\n",
       "4  вот что значит страшилка но блин посмотрев все...            1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также']\n",
    "def  stop_words(text, stopwords = stopw):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords and len(token) > 2])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "здесь лематизацию делать не будем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_bpe(sent):\n",
    "    vec = bpemb_ru.embed(sent)\n",
    "    if len(vec):\n",
    "        return(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        return(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>text_bpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>школота поверь самое общество профилирующий пр...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.014792068, -0.10914229, 0.094901, 0.0275122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>таки немного похож мальчик равно</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.337034, -0.063679755, 0.1094545, 0.0075524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>идиотка испугалась</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.17493764, 0.105021626, 0.22462825, 0.23207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>углу сидит погибает голода порции взяли хотя ж...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.30528587, 0.10548739, 0.0524021, 0.1353126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>значит страшилка блин посмотрев части создастс...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19662201, -0.011566614, -0.03991857, 0.264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive  \\\n",
       "0  школота поверь самое общество профилирующий пр...            1   \n",
       "1                   таки немного похож мальчик равно            1   \n",
       "2                                 идиотка испугалась            1   \n",
       "3  углу сидит погибает голода порции взяли хотя ж...            1   \n",
       "4  значит страшилка блин посмотрев части создастс...            1   \n",
       "\n",
       "                                            text_bpe  \n",
       "0  [0.014792068, -0.10914229, 0.094901, 0.0275122...  \n",
       "1  [-0.337034, -0.063679755, 0.1094545, 0.0075524...  \n",
       "2  [-0.17493764, 0.105021626, 0.22462825, 0.23207...  \n",
       "3  [-0.30528587, 0.10548739, 0.0524021, 0.1353126...  \n",
       "4  [-0.19662201, -0.011566614, -0.03991857, 0.264...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['text_bpe'].tolist()\n",
    "X_test = X_test['text_bpe'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, max_depth=15, min_samples_leaf=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=15, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.605018603748964"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили результат немного хуже чем с word2vec. Теперь проверим какой результат получит нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.activations import tanh, sigmoid\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170125, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "nn_input = Input(shape=(100,))\n",
    "x = Dense(256, activation=tanh)(nn_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation=tanh)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation=tanh)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(1, activation=sigmoid)(x)\n",
    "\n",
    "model = Model(inputs=[nn_input], output=[output] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=4e-3)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='binary_crossentropy',  # функция потерь binary_crossentropy (log loss)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170125/170125 [==============================] - 5s 31us/step - loss: 0.5717 - acc: 0.6967\n",
      "Epoch 2/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.6243 - acc: 0.6438\n",
      "Epoch 3/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5753 - acc: 0.6934\n",
      "Epoch 4/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.6007 - acc: 0.6675\n",
      "Epoch 5/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5947 - acc: 0.6718\n",
      "Epoch 6/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5782 - acc: 0.6899\n",
      "Epoch 7/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5785 - acc: 0.6882\n",
      "Epoch 8/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5851 - acc: 0.6795\n",
      "Epoch 9/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5830 - acc: 0.6833\n",
      "Epoch 10/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5770 - acc: 0.6912\n",
      "Epoch 11/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5754 - acc: 0.6927\n",
      "Epoch 12/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5765 - acc: 0.6904\n",
      "Epoch 13/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5761 - acc: 0.6903\n",
      "Epoch 14/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5744 - acc: 0.6934\n",
      "Epoch 15/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5738 - acc: 0.6946\n",
      "Epoch 16/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5734 - acc: 0.6943\n",
      "Epoch 17/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5720 - acc: 0.6961\n",
      "Epoch 18/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5707 - acc: 0.6985\n",
      "Epoch 19/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5708 - acc: 0.6984\n",
      "Epoch 20/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5714 - acc: 0.6966\n",
      "Epoch 21/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5705 - acc: 0.6975\n",
      "Epoch 22/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5684 - acc: 0.6996\n",
      "Epoch 23/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5677 - acc: 0.7003\n",
      "Epoch 24/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5687 - acc: 0.6990\n",
      "Epoch 25/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5687 - acc: 0.6993\n",
      "Epoch 26/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5672 - acc: 0.7010\n",
      "Epoch 27/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5659 - acc: 0.7024\n",
      "Epoch 28/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5661 - acc: 0.7021\n",
      "Epoch 29/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5664 - acc: 0.7012\n",
      "Epoch 30/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5656 - acc: 0.7018\n",
      "Epoch 31/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5646 - acc: 0.7028\n",
      "Epoch 32/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5642 - acc: 0.7036\n",
      "Epoch 33/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5642 - acc: 0.7039\n",
      "Epoch 34/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5638 - acc: 0.7044\n",
      "Epoch 35/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5631 - acc: 0.7051\n",
      "Epoch 36/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5626 - acc: 0.7048\n",
      "Epoch 37/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5622 - acc: 0.7044\n",
      "Epoch 38/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5619 - acc: 0.7048\n",
      "Epoch 39/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5615 - acc: 0.7057\n",
      "Epoch 40/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5609 - acc: 0.7063\n",
      "Epoch 41/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5604 - acc: 0.7073\n",
      "Epoch 42/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5601 - acc: 0.7077\n",
      "Epoch 43/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5598 - acc: 0.7076\n",
      "Epoch 44/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5591 - acc: 0.7078\n",
      "Epoch 45/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5587 - acc: 0.7081\n",
      "Epoch 46/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5584 - acc: 0.7086\n",
      "Epoch 47/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5579 - acc: 0.7090\n",
      "Epoch 48/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5573 - acc: 0.7093\n",
      "Epoch 49/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5569 - acc: 0.7099\n",
      "Epoch 50/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5565 - acc: 0.7101\n",
      "Epoch 51/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5560 - acc: 0.7103\n",
      "Epoch 52/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5555 - acc: 0.7111\n",
      "Epoch 53/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5551 - acc: 0.7112\n",
      "Epoch 54/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5546 - acc: 0.7116\n",
      "Epoch 55/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5541 - acc: 0.7120\n",
      "Epoch 56/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5536 - acc: 0.7122\n",
      "Epoch 57/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5531 - acc: 0.7126\n",
      "Epoch 58/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5526 - acc: 0.7130\n",
      "Epoch 59/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5521 - acc: 0.7136\n",
      "Epoch 60/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5516 - acc: 0.7141\n",
      "Epoch 61/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5511 - acc: 0.7143\n",
      "Epoch 62/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5506 - acc: 0.7147\n",
      "Epoch 63/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5501 - acc: 0.7153\n",
      "Epoch 64/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5496 - acc: 0.7158\n",
      "Epoch 65/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5491 - acc: 0.7160\n",
      "Epoch 66/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5485 - acc: 0.7164\n",
      "Epoch 67/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5480 - acc: 0.7168\n",
      "Epoch 68/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5474 - acc: 0.7173\n",
      "Epoch 69/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5469 - acc: 0.7179\n",
      "Epoch 70/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5463 - acc: 0.7186\n",
      "Epoch 71/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5458 - acc: 0.7191\n",
      "Epoch 72/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5452 - acc: 0.7194\n",
      "Epoch 73/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5447 - acc: 0.7199\n",
      "Epoch 74/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5441 - acc: 0.7204\n",
      "Epoch 75/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5435 - acc: 0.7209\n",
      "Epoch 76/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5429 - acc: 0.7213\n",
      "Epoch 77/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5424 - acc: 0.7219\n",
      "Epoch 78/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5418 - acc: 0.7221\n",
      "Epoch 79/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5412 - acc: 0.7225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5406 - acc: 0.7230\n",
      "Epoch 81/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5400 - acc: 0.7238\n",
      "Epoch 82/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5394 - acc: 0.7243\n",
      "Epoch 83/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5388 - acc: 0.7247\n",
      "Epoch 84/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5381 - acc: 0.7251\n",
      "Epoch 85/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5375 - acc: 0.7257\n",
      "Epoch 86/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5369 - acc: 0.7262\n",
      "Epoch 87/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5363 - acc: 0.7268\n",
      "Epoch 88/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5356 - acc: 0.7273\n",
      "Epoch 89/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5350 - acc: 0.7278\n",
      "Epoch 90/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5343 - acc: 0.7285\n",
      "Epoch 91/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5337 - acc: 0.7290\n",
      "Epoch 92/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5330 - acc: 0.7294\n",
      "Epoch 93/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5323 - acc: 0.7298\n",
      "Epoch 94/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5316 - acc: 0.7303\n",
      "Epoch 95/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5310 - acc: 0.7309\n",
      "Epoch 96/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5303 - acc: 0.7314\n",
      "Epoch 97/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5296 - acc: 0.7320\n",
      "Epoch 98/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5289 - acc: 0.7325\n",
      "Epoch 99/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5282 - acc: 0.7330\n",
      "Epoch 100/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5275 - acc: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a8c2e7128>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=200000, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred<0.5] = int(0)\n",
    "y_pred[y_pred>0.5] = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.601033345677053"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не очень хороший и похоже наша сеть немного переучилась. Теперь будем не усреднять эмбединги, а подадим их в рекурентную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import LSTM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    226834.000000\n",
       "mean         14.117121\n",
       "std           8.225647\n",
       "min           1.000000\n",
       "50%          13.000000\n",
       "70%          17.000000\n",
       "80%          20.000000\n",
       "90%          24.000000\n",
       "95%          27.000000\n",
       "max         111.000000\n",
       "Name: opt_num, dtype: float64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['opt_num'] = df['text_bpe'].apply(lambda x: x.shape[0])\n",
    "df.opt_num.describe(percentiles=[0.7, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что 25 \"Bpemp\"  описывает более 90% всех предложений. Это количесво последовательности и возьмем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_bpe_full(sent):\n",
    "    vec = bpemb_ru.embed(sent)\n",
    "    if len(vec):\n",
    "        return(vec)\n",
    "    else:\n",
    "        return(np.zeros(100).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe_full(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['text_bpe'].tolist()\n",
    "X_test = X_test['text_bpe'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetValues(words):\n",
    "    return bpemb_ru.encode_ids(words)\n",
    "def GetWords(values):\n",
    "    return bpemb_ru.decode_ids(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BpeDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = bpemb_ru.vocab_size\n",
    "        self.data = X_train\n",
    "        self.target = y_train\n",
    "        self.eos = bpemb_ru.vectors[bpemb_ru.EOS].tolist()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target.iloc[index]\n",
    "        x_list = x[1:].tolist()\n",
    "        x_list.append(self.eos)\n",
    "        y_for_seq2seq = np.array(x_list)\n",
    "        return x, y     \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = BpeDataset()\n",
    "trn_dl = DataLoader(trn_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, input_size=100, hidden_size=50, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.out = nn.Linear(hidden_size, bpemb_ru.vocab_size)\n",
    "        self.vocab_size = bpemb_ru.vocab_size\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x, c_prev, h_prev):\n",
    "        x = x.float()\n",
    "        lstm_out, (c_prev, h_prev) = self.lstm(x, (c_prev, h_prev))\n",
    "        tag_space = self.classifier(lstm_out.view(len(x), -1))\n",
    "        return tag_space, (c_prev, h_prev)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "model = LSTMmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        optimizer.zero_grad()\n",
    "        c_prev = torch.zeros([1, 1, hidden_size], dtype=torch.float, device='cpu')\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        x, y = x.to(\"cpu\"), y.to(\"cpu\")\n",
    "        for i in range(x.shape[1]):\n",
    "            y_pred, (c_prev, h_prev)  = model.forward(x[:, i].view(1, 1, -1), c_prev, h_prev)\n",
    "            y_true = torch.tensor(y.view(1, -1)).float()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "    \n",
    "         \n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if line_num % 3000 == 0:\n",
    "            print (line_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        print('Epoch:{}'.format(e))\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:2\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:3\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:4\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:5\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:6\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:7\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:8\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:9\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n",
      "111000\n",
      "114000\n",
      "117000\n",
      "120000\n",
      "123000\n",
      "126000\n",
      "129000\n",
      "132000\n",
      "135000\n",
      "138000\n",
      "141000\n",
      "144000\n",
      "147000\n",
      "150000\n",
      "153000\n",
      "156000\n",
      "159000\n",
      "162000\n",
      "165000\n",
      "168000\n",
      "Epoch:10\n",
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n",
      "21000\n",
      "24000\n",
      "27000\n",
      "30000\n",
      "33000\n",
      "36000\n",
      "39000\n",
      "42000\n",
      "45000\n",
      "48000\n",
      "51000\n",
      "54000\n",
      "57000\n",
      "60000\n",
      "63000\n",
      "66000\n",
      "69000\n",
      "72000\n",
      "75000\n",
      "78000\n",
      "81000\n",
      "84000\n",
      "87000\n",
      "90000\n",
      "93000\n",
      "96000\n",
      "99000\n",
      "102000\n",
      "105000\n",
      "108000\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой плохой результат получается вероятно по тому, что мы работаем с моделью обученной на Википедиа, что для анализа Твитера не очень подходит. И к тому же суммирование всех векторов тоже делать не очень правильно. Но дообучать её не будем, а пойдем дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\Илья Курошев\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\Илья Курошев\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\8EA2~1\\AppData\\Local\\Temp\\tmppxt_46n2\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "assert len(encoded_layers) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\Илья Курошев\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\Илья Курошев\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\8EA2~1\\AppData\\Local\\Temp\\tmpsltiwiol\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'henson'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
