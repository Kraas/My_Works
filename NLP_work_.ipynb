{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация твитов по тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале очистим наш текст. Уберем стоп слова, цыфры, символы. Лемматизацию делать не будем, так как как для получения embedding-а будем использовать BPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'date', 'name', 'text', 'type', 'rep', 'rtw', 'fav', 'stcount', \n",
    "            'fol', 'frien', 'listcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv('Data/positive.csv', sep=';',  names=columns)\n",
    "negative = pd.read_csv('Data/negative.csv', sep=';',  names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive['is_positive'] = 1\n",
    "negative['is_positive'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtw</th>\n",
       "      <th>fav</th>\n",
       "      <th>stcount</th>\n",
       "      <th>fol</th>\n",
       "      <th>frien</th>\n",
       "      <th>listcount</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906762813579264</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906818262687744</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906858515398656</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        date             name  \\\n",
       "0  408906762813579264  1386325944  dugarchikbellko   \n",
       "1  408906818262687744  1386325957     nugemycejela   \n",
       "2  408906858515398656  1386325966          4post21   \n",
       "\n",
       "                                                text  type  rep  rtw  fav  \\\n",
       "0  на работе был полный пиддес :| и так каждое за...    -1    0    0    0   \n",
       "1  Коллеги сидят рубятся в Urban terror, а я из-з...    -1    0    0    0   \n",
       "2  @elina_4post как говорят обещаного три года жд...    -1    0    0    0   \n",
       "\n",
       "   stcount  fol  frien  listcount  is_positive  \n",
       "0     8064  111     94          2            0  \n",
       "1       26   42     39          0            0  \n",
       "2      718   49    249          0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (positive.append(negative)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114911, 13), (111923, 13), (226834, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.shape, negative.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[['text', 'is_positive']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = re.compile('[А-Яа-я]+')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(re.findall(word, x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота но поверь у нас то же самое о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>да все таки он немного похож на него но мой ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ну ты идиотка я испугалась за тебя</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кто то в углу сидит и погибает от голода а мы ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вот что значит страшилка но блин посмотрев все...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive\n",
       "0  хоть я и школота но поверь у нас то же самое о...            1\n",
       "1  да все таки он немного похож на него но мой ма...            1\n",
       "2                 ну ты идиотка я испугалась за тебя            1\n",
       "3  кто то в углу сидит и погибает от голода а мы ...            1\n",
       "4  вот что значит страшилка но блин посмотрев все...            1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from bpemb import BPEmb\n",
    "from pathlib import WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_ru = BPEmb(lang=\"ru\", dim=100, cache_dir = WindowsPath('C:\\My Programs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (positive.append(negative)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[['text', 'is_positive']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = re.compile('[А-Яа-я]+')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(re.findall(word, x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота но поверь у нас то же самое о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>да все таки он немного похож на него но мой ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ну ты идиотка я испугалась за тебя</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кто то в углу сидит и погибает от голода а мы ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>вот что значит страшилка но блин посмотрев все...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive\n",
       "0  хоть я и школота но поверь у нас то же самое о...            1\n",
       "1  да все таки он немного похож на него но мой ма...            1\n",
       "2                 ну ты идиотка я испугалась за тебя            1\n",
       "3  кто то в углу сидит и погибает от голода а мы ...            1\n",
       "4  вот что значит страшилка но блин посмотрев все...            1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также']\n",
    "def  stop_words(text, stopwords = stopw):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords and len(token) > 2])\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: stop_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим сами embedding для слов, усредним их на каждом предложении и отдадим в качестве признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_bpe(sent):\n",
    "    vec = bpemb_ru.embed(sent)\n",
    "    if len(vec):\n",
    "        return(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        return(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>text_bpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>школота поверь самое общество профилирующий пр...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.014792068, -0.10914229, 0.094901, 0.0275122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>таки немного похож мальчик равно</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.337034, -0.063679755, 0.1094545, 0.0075524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>идиотка испугалась</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.17493764, 0.105021626, 0.22462825, 0.23207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>углу сидит погибает голода порции взяли хотя ж...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.30528587, 0.10548739, 0.0524021, 0.1353126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>значит страшилка блин посмотрев части создастс...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19662201, -0.011566614, -0.03991857, 0.264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_positive  \\\n",
       "0  школота поверь самое общество профилирующий пр...            1   \n",
       "1                   таки немного похож мальчик равно            1   \n",
       "2                                 идиотка испугалась            1   \n",
       "3  углу сидит погибает голода порции взяли хотя ж...            1   \n",
       "4  значит страшилка блин посмотрев части создастс...            1   \n",
       "\n",
       "                                            text_bpe  \n",
       "0  [0.014792068, -0.10914229, 0.094901, 0.0275122...  \n",
       "1  [-0.337034, -0.063679755, 0.1094545, 0.0075524...  \n",
       "2  [-0.17493764, 0.105021626, 0.22462825, 0.23207...  \n",
       "3  [-0.30528587, 0.10548739, 0.0524021, 0.1353126...  \n",
       "4  [-0.19662201, -0.011566614, -0.03991857, 0.264...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим 25% положительных и 25% отрицательных твитов как тестовую выборку. И попробуем классифицироватьнаши твиты с помощью нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['text_bpe'].tolist()\n",
    "X_test = X_test['text_bpe'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.activations import tanh, sigmoid\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170125, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "nn_input = Input(shape=(100,))\n",
    "x = Dense(256, activation=tanh)(nn_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation=tanh)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation=tanh)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(1, activation=sigmoid)(x)\n",
    "\n",
    "model = Model(inputs=[nn_input], output=[output] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=4e-3)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='binary_crossentropy',  # функция потерь binary_crossentropy (log loss)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170125/170125 [==============================] - 5s 31us/step - loss: 0.5717 - acc: 0.6967\n",
      "Epoch 2/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.6243 - acc: 0.6438\n",
      "Epoch 3/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5753 - acc: 0.6934\n",
      "Epoch 4/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.6007 - acc: 0.6675\n",
      "Epoch 5/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5947 - acc: 0.6718\n",
      "Epoch 6/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5782 - acc: 0.6899\n",
      "Epoch 7/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5785 - acc: 0.6882\n",
      "Epoch 8/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5851 - acc: 0.6795\n",
      "Epoch 9/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5830 - acc: 0.6833\n",
      "Epoch 10/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5770 - acc: 0.6912\n",
      "Epoch 11/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5754 - acc: 0.6927\n",
      "Epoch 12/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5765 - acc: 0.6904\n",
      "Epoch 13/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5761 - acc: 0.6903\n",
      "Epoch 14/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5744 - acc: 0.6934\n",
      "Epoch 15/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5738 - acc: 0.6946\n",
      "Epoch 16/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5734 - acc: 0.6943\n",
      "Epoch 17/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5720 - acc: 0.6961\n",
      "Epoch 18/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5707 - acc: 0.6985\n",
      "Epoch 19/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5708 - acc: 0.6984\n",
      "Epoch 20/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5714 - acc: 0.6966\n",
      "Epoch 21/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5705 - acc: 0.6975\n",
      "Epoch 22/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5684 - acc: 0.6996\n",
      "Epoch 23/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5677 - acc: 0.7003\n",
      "Epoch 24/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5687 - acc: 0.6990\n",
      "Epoch 25/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5687 - acc: 0.6993\n",
      "Epoch 26/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5672 - acc: 0.7010\n",
      "Epoch 27/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5659 - acc: 0.7024\n",
      "Epoch 28/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5661 - acc: 0.7021\n",
      "Epoch 29/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5664 - acc: 0.7012\n",
      "Epoch 30/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5656 - acc: 0.7018\n",
      "Epoch 31/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5646 - acc: 0.7028\n",
      "Epoch 32/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5642 - acc: 0.7036\n",
      "Epoch 33/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5642 - acc: 0.7039\n",
      "Epoch 34/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5638 - acc: 0.7044\n",
      "Epoch 35/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5631 - acc: 0.7051\n",
      "Epoch 36/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5626 - acc: 0.7048\n",
      "Epoch 37/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5622 - acc: 0.7044\n",
      "Epoch 38/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5619 - acc: 0.7048\n",
      "Epoch 39/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5615 - acc: 0.7057\n",
      "Epoch 40/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5609 - acc: 0.7063\n",
      "Epoch 41/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5604 - acc: 0.7073\n",
      "Epoch 42/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5601 - acc: 0.7077\n",
      "Epoch 43/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5598 - acc: 0.7076\n",
      "Epoch 44/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5591 - acc: 0.7078\n",
      "Epoch 45/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5587 - acc: 0.7081\n",
      "Epoch 46/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5584 - acc: 0.7086\n",
      "Epoch 47/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5579 - acc: 0.7090\n",
      "Epoch 48/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5573 - acc: 0.7093\n",
      "Epoch 49/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5569 - acc: 0.7099\n",
      "Epoch 50/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5565 - acc: 0.7101\n",
      "Epoch 51/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5560 - acc: 0.7103\n",
      "Epoch 52/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5555 - acc: 0.7111\n",
      "Epoch 53/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5551 - acc: 0.7112\n",
      "Epoch 54/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5546 - acc: 0.7116\n",
      "Epoch 55/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5541 - acc: 0.7120\n",
      "Epoch 56/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5536 - acc: 0.7122\n",
      "Epoch 57/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5531 - acc: 0.7126\n",
      "Epoch 58/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5526 - acc: 0.7130\n",
      "Epoch 59/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5521 - acc: 0.7136\n",
      "Epoch 60/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5516 - acc: 0.7141\n",
      "Epoch 61/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5511 - acc: 0.7143\n",
      "Epoch 62/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5506 - acc: 0.7147\n",
      "Epoch 63/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5501 - acc: 0.7153\n",
      "Epoch 64/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5496 - acc: 0.7158\n",
      "Epoch 65/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5491 - acc: 0.7160\n",
      "Epoch 66/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5485 - acc: 0.7164\n",
      "Epoch 67/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5480 - acc: 0.7168\n",
      "Epoch 68/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5474 - acc: 0.7173\n",
      "Epoch 69/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5469 - acc: 0.7179\n",
      "Epoch 70/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5463 - acc: 0.7186\n",
      "Epoch 71/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5458 - acc: 0.7191\n",
      "Epoch 72/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5452 - acc: 0.7194\n",
      "Epoch 73/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5447 - acc: 0.7199\n",
      "Epoch 74/100\n",
      "170125/170125 [==============================] - 3s 20us/step - loss: 0.5441 - acc: 0.7204\n",
      "Epoch 75/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5435 - acc: 0.7209\n",
      "Epoch 76/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5429 - acc: 0.7213\n",
      "Epoch 77/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5424 - acc: 0.7219\n",
      "Epoch 78/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5418 - acc: 0.7221\n",
      "Epoch 79/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5412 - acc: 0.7225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5406 - acc: 0.7230\n",
      "Epoch 81/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5400 - acc: 0.7238\n",
      "Epoch 82/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5394 - acc: 0.7243\n",
      "Epoch 83/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5388 - acc: 0.7247\n",
      "Epoch 84/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5381 - acc: 0.7251\n",
      "Epoch 85/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5375 - acc: 0.7257\n",
      "Epoch 86/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5369 - acc: 0.7262\n",
      "Epoch 87/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5363 - acc: 0.7268\n",
      "Epoch 88/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5356 - acc: 0.7273\n",
      "Epoch 89/100\n",
      "170125/170125 [==============================] - 4s 21us/step - loss: 0.5350 - acc: 0.7278\n",
      "Epoch 90/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5343 - acc: 0.7285\n",
      "Epoch 91/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5337 - acc: 0.7290\n",
      "Epoch 92/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5330 - acc: 0.7294\n",
      "Epoch 93/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5323 - acc: 0.7298\n",
      "Epoch 94/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5316 - acc: 0.7303\n",
      "Epoch 95/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5310 - acc: 0.7309\n",
      "Epoch 96/100\n",
      "170125/170125 [==============================] - 3s 18us/step - loss: 0.5303 - acc: 0.7314\n",
      "Epoch 97/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5296 - acc: 0.7320\n",
      "Epoch 98/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5289 - acc: 0.7325\n",
      "Epoch 99/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5282 - acc: 0.7330\n",
      "Epoch 100/100\n",
      "170125/170125 [==============================] - 3s 19us/step - loss: 0.5275 - acc: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a8c2e7128>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=200000, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred<0.5] = int(0)\n",
    "y_pred[y_pred>0.5] = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.601033345677053"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не очень хороший и похоже наша сеть немного переобучилась. Но настраивать её сейчас не будем. Вместо этого теперь будем не усреднять эмбединги, а подадим их в рекурентную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import LSTM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    226834.000000\n",
       "mean         14.117121\n",
       "std           8.225647\n",
       "min           1.000000\n",
       "50%          13.000000\n",
       "70%          17.000000\n",
       "80%          20.000000\n",
       "90%          24.000000\n",
       "95%          27.000000\n",
       "max         111.000000\n",
       "Name: opt_num, dtype: float64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['opt_num'] = df['text_bpe'].apply(lambda x: x.shape[0])\n",
    "df.opt_num.describe(percentiles=[0.7, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_bpe_full(sent):\n",
    "    vec = bpemb_ru.embed(sent)\n",
    "    if len(vec):\n",
    "        return(vec)\n",
    "    else:\n",
    "        return(np.zeros(100).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bpe'] = df['text'].apply(lambda x: sent_to_bpe_full(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 13)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['is_positive']):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    y_train = df['is_positive'].iloc[train_index]\n",
    "    y_test = df['is_positive'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['text_bpe'].tolist()\n",
    "X_test = X_test['text_bpe'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetValues(words):\n",
    "    return bpemb_ru.encode_ids(words)\n",
    "def GetWords(values):\n",
    "    return bpemb_ru.decode_ids(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BpeDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = bpemb_ru.vocab_size\n",
    "        self.data = X_train\n",
    "        self.target = y_train\n",
    "        self.eos = bpemb_ru.vectors[bpemb_ru.EOS].tolist()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target.iloc[index]\n",
    "        x_list = x[1:].tolist()\n",
    "        x_list.append(self.eos)\n",
    "        y_for_seq2seq = np.array(x_list)\n",
    "        return x, y     \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = BpeDataset()\n",
    "trn_dl = DataLoader(trn_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, input_size=100, hidden_size=50, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.out = nn.Linear(hidden_size, bpemb_ru.vocab_size)\n",
    "        self.vocab_size = bpemb_ru.vocab_size\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x, c_prev, h_prev):\n",
    "        x = x.float()\n",
    "        lstm_out, (c_prev, h_prev) = self.lstm(x, (c_prev, h_prev))\n",
    "        tag_space = self.classifier(lstm_out.view(len(x), -1))\n",
    "        return tag_space, (c_prev, h_prev)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "model = LSTMmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        optimizer.zero_grad()\n",
    "        c_prev = torch.zeros([1, 1, hidden_size], dtype=torch.float, device='cpu')\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        x, y = x.to(\"cpu\"), y.to(\"cpu\")\n",
    "        for i in range(x.shape[1]):\n",
    "            y_pred, (c_prev, h_prev)  = model.forward(x[:, i].view(1, 1, -1), c_prev, h_prev)\n",
    "            y_true = torch.tensor(y.view(1, -1)).float()\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "    \n",
    "         \n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if line_num % 10000 == 0:\n",
    "            print (line_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        print('Epoch:{}'.format(e))\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(model, loss_fn, optimizer, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"rnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = torch.load(\"rnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BpeDataset_test(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = X_test\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        return x    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds_test = BpeDataset_test()\n",
    "trn_dl_test = DataLoader(trn_ds_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model):\n",
    "    list_predict = []\n",
    "    for line_num, x in enumerate(trn_dl_test):\n",
    "        c_prev = torch.zeros([1, 1, hidden_size], dtype=torch.float, device='cpu')\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        x = x.to(\"cpu\")\n",
    "        for i in range(x.shape[1]):\n",
    "            y_pred, (c_prev, h_prev)  = model.forward(x[:, i].view(1, 1, -1), c_prev, h_prev)\n",
    "        list_predict.append(y_pred)\n",
    "    return list_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "for i in y_pred:\n",
    "    list_pred.append(1 if float(i.view(-1)) > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6722742421837804"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, list_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что результат на RNN получается лучше. Так же для более качественного предсказания нужно реализовать attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
